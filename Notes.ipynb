{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Notes: Comparison of Setup Time Handling in MIP vs. Brute Force Approach\n",
    "\n",
    "#### 1. **Overview of the Methods**\n",
    "   - **Brute Force**: This approach evaluates every possible permutation of orders, calculating the corresponding objective value (profit) for each sequence while considering constraints like setup times, deadlines, and tardiness.\n",
    "   - **MIP (Mixed-Integer Programming)**: The MIP approach leverages a mathematical optimization solver (e.g., Gurobi) that uses advanced techniques like **branch-and-bound**, **constraint relaxation**, and **cutting planes** to find the optimal solution efficiently.\n",
    "\n",
    "#### 2. **Handling of Setup Times**\n",
    "   - **Brute Force Handling of Setup Times**:\n",
    "     - In brute force, the setup times are considered after evaluating each order sequence.\n",
    "     - For each permutation of the orders, the setup time between consecutive jobs is added to the cost after the sequence is determined.\n",
    "     - The approach does not dynamically optimize over setup times across different sequences; it merely computes the setup time for each fixed sequence without considering how adjustments to the sequence might reduce overall setup costs.\n",
    "     - As a result, brute force may fail to efficiently exploit opportunities to minimize setup times across multiple sequences.\n",
    "\n",
    "   - **MIP Handling of Setup Times**:\n",
    "     - The MIP model directly incorporates **sequence-dependent setup times** into the optimization process as part of the decision variables.\n",
    "     - Setup times are considered **dynamically** while the solver searches for an optimal sequence. The solver adjusts the sequence of jobs in real-time to minimize both setup times and the total cost (profit, tardiness, and setup).\n",
    "     - **Constraint Handling**: The MIP solver enforces the constraints related to setup times, such as ensuring that the setup time between consecutive jobs is correctly added to the total cost. The solver also considers setup time in the objective function, enabling it to find solutions that reduce setup costs.\n",
    "\n",
    "#### 3. **Profit Calculation and Setup Time Optimization**\n",
    "   - **Brute Force**:\n",
    "     - Profit is calculated after each sequence is determined, but setup times are not optimized directly. The brute force method evaluates the profit for each sequence and checks if it exceeds the deadline or tardiness constraints.\n",
    "     - Because it does not consider setup times when generating the sequences, the brute force approach may end up evaluating suboptimal sequences where high setup times are incurred, leading to lower overall profits.\n",
    "     - Brute force tends to be computationally expensive, especially when there are a large number of possible order sequences, since it evaluates every possible combination regardless of how setup times might affect the total cost.\n",
    "\n",
    "   - **MIP**:\n",
    "     - The MIP model explicitly integrates **setup times** into the objective function, meaning it directly affects the profit calculation.\n",
    "     - Since the solver is optimized to find the sequence with the **maximum profit**, it will minimize the setup time by adjusting the order of tasks dynamically.\n",
    "     - The solver considers both tardiness and setup costs in the optimization process, ensuring that the final solution minimizes both tardiness penalties and unnecessary setup costs.\n",
    "     - The MIP approach’s ability to handle setup times dynamically leads to more efficient and often more profitable solutions.\n",
    "\n",
    "#### 4. **Feasibility and Constraint Handling**\n",
    "   - **Brute Force**:\n",
    "     - Brute force evaluates all possible sequences, but it checks the feasibility of each solution after the sequence is determined. If any sequence violates constraints (e.g., deadlines, tardiness), it is discarded.\n",
    "     - This leads to a more time-consuming search process since the algorithm checks all permutations of orders and then filters out infeasible ones.\n",
    "     - Setup times are only considered once a sequence is evaluated, which may result in unnecessary setups between orders that could otherwise be minimized.\n",
    "\n",
    "   - **MIP**:\n",
    "     - The MIP solver integrates constraint handling directly into the optimization process. For example, constraints on **precedence**, **setup times**, and **tardiness** are enforced **during** the solution search.\n",
    "     - The solver also takes into account **sequence-dependent setup times** when generating the optimal order sequence, ensuring that the sequence with the least setup time is selected first.\n",
    "     - This more sophisticated handling of constraints allows the MIP model to find better solutions in less time than brute force, especially for larger problem sizes.\n",
    "\n",
    "#### 5. **Efficiency and Computation**\n",
    "   - **Brute Force**:\n",
    "     - Brute force evaluates every permutation of the orders exhaustively, which can be computationally expensive, especially for large instances where the number of permutations grows exponentially.\n",
    "     - Since the brute force method doesn’t leverage any optimization techniques, it evaluates each solution independently, which can lead to inefficiencies in finding the optimal solution.\n",
    "     - As a result, brute force may miss the best sequence, especially in cases with complex interactions between setup times and tardiness costs.\n",
    "\n",
    "   - **MIP**:\n",
    "     - The MIP approach uses advanced optimization techniques like **branch-and-bound**, **constraint propagation**, and **heuristics** to explore the solution space efficiently.\n",
    "     - It can explore feasible solutions quickly by pruning infeasible branches and focusing on high-quality solutions.\n",
    "     - This efficiency allows MIP to find better solutions faster, particularly in large problem instances where the number of potential sequences is large.\n",
    "\n",
    "#### 6. **Conclusion: Setup Time Handling and Profit Differences**\n",
    "   - **Brute Force**:\n",
    "     - While brute force evaluates all possible solutions, it does so in a non-optimized manner, leading to inefficiencies in handling setup times.\n",
    "     - The lack of dynamic optimization over setup times means that brute force might fail to minimize setup costs, which can reduce overall profit.\n",
    "     - In complex scheduling problems, brute force may also miss opportunities to exploit the interactions between setup times and tardiness, leading to suboptimal results.\n",
    "\n",
    "   - **MIP**:\n",
    "     - The MIP model integrates setup times directly into the optimization process, allowing for a more effective exploration of sequences that minimize setup costs.\n",
    "     - By incorporating setup times into the objective function and constraints, MIP can efficiently find the sequence with the highest profit, taking into account all factors (including tardiness and setup costs).\n",
    "     - The ability to dynamically adjust sequences during the optimization process leads to better solutions that maximize profit while minimizing setup costs.\n",
    "\n",
    "#### 7. **Why MIP Can Outperform Brute Force in Profit**\n",
    "   - The **MIP approach** outperforms brute force because it considers setup times as part of the optimization process, dynamically adjusting the sequence of orders to minimize setup costs.\n",
    "   - The solver is able to consider **all constraints simultaneously** and optimize the solution as a whole, rather than evaluating each sequence independently.\n",
    "   - **Brute force** does not have the capacity to leverage advanced optimization methods, making it more likely to miss the optimal solution, especially in complex problems with many variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluating Runtime Complexity and Memory Usage of Heuristics\n",
    "\n",
    "### 1. **Insertion Heuristic**\n",
    "   - **Runtime Complexity:**\n",
    "     - Typically, the **Insertion** heuristic has a **time complexity of O(n^2)**, where `n` is the number of orders. This is because, for each order, we potentially check each position in the schedule to determine where it should be inserted.\n",
    "     - **Worst Case:** If each order must be compared with all others, this results in quadratic complexity.\n",
    "   - **Memory Usage:**\n",
    "     - The **Insertion** heuristic has **O(n)** memory usage, where `n` is the number of orders. This is primarily for storing the list of orders and their properties (such as durations, profits, etc.). Additional memory might be used if intermediate structures (e.g., score lists) are created.\n",
    "\n",
    "### 2. **Savings Heuristic**\n",
    "   - **Runtime Complexity:**\n",
    "     - The **Savings** heuristic typically has a **time complexity of O(n^2)**. This is because for each pair of orders, the heuristic computes the savings of scheduling the pair together and then iterates through all orders.\n",
    "     - **Worst Case:** The savings computation requires considering all pairs, leading to quadratic complexity.\n",
    "   - **Memory Usage:**\n",
    "     - Memory usage for the **Savings** heuristic is **O(n^2)**. This includes storing savings for every possible pair of orders, along with their schedules and any related decision-making data.\n",
    "\n",
    "### 3. **Construct Heuristic**\n",
    "   - **Runtime Complexity:**\n",
    "     - The **Construct** heuristic generally has a **time complexity of O(n^2)** to **O(n^3)**, depending on the complexity of the scoring function and the number of feasibility checks.\n",
    "     - The heuristic iterates through all remaining orders and computes a score for each, which can involve comparisons and feasibility checks, leading to quadratic or cubic complexity.\n",
    "   - **Memory Usage:**\n",
    "     - Memory usage is usually **O(n)** for storing the schedule and possibly additional arrays to track remaining orders and their scores.\n",
    "\n",
    "### 4. **Move Heuristic**\n",
    "   - **Runtime Complexity:**\n",
    "     - The **Move** heuristic typically has a **time complexity of O(n^2)**, where `n` is the number of orders.\n",
    "     - In the **Move** heuristic, the algorithm performs local search by checking different possible swaps or moves for each order. This requires multiple passes over the orders, and thus, the time complexity can be quadratic.\n",
    "   - **Memory Usage:**\n",
    "     - **O(n)** space complexity is common, as it stores the current schedule and potentially a few auxiliary variables for scoring and temporary changes.\n",
    "\n",
    "### 5. **Swap Heuristic**\n",
    "   - **Runtime Complexity:**\n",
    "     - Similar to the **Move** heuristic, the **Swap** heuristic has **O(n^2)** time complexity. The algorithm tries to swap different orders in the schedule, and for each swap, it checks if the new arrangement improves the solution.\n",
    "   - **Memory Usage:**\n",
    "     - **O(n)** memory usage for storing the list of orders and their properties, as well as any temporary data structures (e.g., for tracking swaps).\n",
    "\n",
    "### 6. **Improve Heuristic**\n",
    "   - **Runtime Complexity:**\n",
    "     - The **Improve** heuristic usually has **O(n^2)** to **O(n^3)** time complexity, depending on the number of iterations and the number of swaps or moves performed in each iteration.\n",
    "     - The complexity can vary based on how many iterations are allowed to improve the solution, and how many comparisons are made in each iteration.\n",
    "   - **Memory Usage:**\n",
    "     - Memory usage for the **Improve** heuristic is typically **O(n)**, but if multiple copies of the schedule are kept for comparison (e.g., for tracking improvements), the space complexity could grow.\n",
    "\n",
    "### General Considerations:\n",
    "\n",
    "- **Time Complexity:**\n",
    "  - The time complexities of all the heuristics (Insertion, Savings, Construct, Move, Swap, and Improve) are generally **O(n^2)**. The exact runtime can vary depending on the problem size and the specific implementation, but it is typically dominated by the nested loops over orders.\n",
    "  - **Worst-case time complexity** for all these heuristics tends to be quadratic, but some can have cubic or higher complexities if they involve multiple nested iterations or if they perform detailed feasibility checks.\n",
    "\n",
    "- **Memory Usage:**\n",
    "  - Most of these heuristics have a **space complexity of O(n)**, primarily due to storing the schedule and related data (durations, profits, etc.).\n",
    "  - Some heuristics like **Savings** may use **O(n^2)** memory for storing pairwise savings or temporary structures during execution.\n",
    "  - **Memory bottlenecks** may occur in heuristics that store intermediate results for every possible pair of orders or keep multiple schedules during optimization.\n",
    "\n",
    "### Comparison Table\n",
    "\n",
    "| **Heuristic**   | **Runtime Complexity** | **Memory Usage** |\n",
    "|-----------------|------------------------|------------------|\n",
    "| **Insertion**    | O(n^2)                 | O(n)             |\n",
    "| **Savings**      | O(n^2)                 | O(n^2)           |\n",
    "| **Construct**    | O(n^2) to O(n^3)       | O(n)             |\n",
    "| **Move**         | O(n^2)                 | O(n)             |\n",
    "| **Swap**         | O(n^2)                 | O(n)             |\n",
    "| **Improve**      | O(n^2) to O(n^3)       | O(n)             |\n",
    "\n",
    "### Summary:\n",
    "- **Runtime Complexity:** Most of the heuristics have **O(n^2)** complexity, with potential to reach **O(n^3)** depending on specific implementations or optimizations.\n",
    "- **Memory Usage:** Generally **O(n)**, but the **Savings** heuristic has higher memory requirements due to pairwise savings storage.\n",
    "```\n",
    "\n",
    "This Markdown format includes the detailed breakdown of runtime complexity and memory usage for the various heuristics, as well as a comparison table for easy reference. If you need any further modifications or have more questions, feel free to let me know!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
